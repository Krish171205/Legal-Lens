# ğŸ“„ LegalLens â€“ AI-Powered Legal Document Assistant

**LegalLens** is an intelligent legal document assistant that extracts, summarizes, and provides contextual legal assistance using **LLMs via Ollama**, **BigBird Pegasus**, and **RAG-based chatbot** powered by **Mistral** and **Pinecone**. The system is designed to handle multilingual legal documents from various formats including PDF, DOCX, DOC, TXT, and images.

---

## ğŸ”§ Project Structure
```
Legal-lens/
â”œâ”€â”€ extraction/
â”‚   â””â”€â”€ extraction.py
â”œâ”€â”€ nlp/
â”‚   â”œâ”€â”€ summarizer.py
â”‚   â””â”€â”€ rag.py
â”œâ”€â”€ webapp/
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html
â”œâ”€â”€ requirements.txt
â””â”€â”€ readme.md
```

---

## ğŸŒ Features

- **Multi-format Document Extraction**:
  - PDF, DOCX, DOC, TXT, and common image formats
  - OCR support using `pytesseract` and `pdfplumber`
  
- **Multilingual Support**:
  - 17+ languages including Hindi, Marathi, Gujarati, Tamil, Bengali, etc.
  
- **Summarization**:
  - Legal text summarization using **BigBird Pegasus** for better long-text compression

- **RAG-based Legal Chatbot**:
  - Semantic search using **Pinecone**
  - Local query embedding and response generation using **Mistral 7B via Ollama**

- **Fully Modular Architecture**:
  - Clean codebase with `services/` for text extraction, summarization, and chatbot logic

- **Frontend in Flask**:
  - User uploads documents or enters raw legal text
  - Chat interface for legal Q&A powered by local models

---

## âš™ï¸ Installation & Setup

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/legallens.git
cd legallens
```

### 2. Create Virtual Environment & Install Dependencies
```
python3 -m venv venv
source venv/bin/activate  # on Windows use venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Install Ollama & Pull Required Models
Install Ollama: https://ollama.com/download
Then pull models:
```
ollama pull mistral
ollama pull bigbird-pegasus
```

### 4. Set Environment Variables
Create a .env file in the root:
```
PINECONE_API_KEY=your_key
PINECONE_ENV=your_env
PINECONE_INDEX_NAME=your_index
```

### 5. Run the Application
```
python backend/app.py
```
Then visit http://localhost:5000 in your browser.

---
# ğŸ“¥ Input Formats Supported
---
| Format           | Support | Notes                                |
|------------------|---------|--------------------------------------|
| ``` .pdf ```             | âœ…      | OCR fallback for scanned pages      |
| ``` .docx ```            | âœ…      | Parsed via ``` python-docx ```              |
| ```.doc```             | âœ…      | Extracted via ```catdoc```                |
| ```.txt```             | âœ…      | Direct text read                    |
| ```.jpg```, ```.png```, ```.tiff```, etc. | âœ… | OCR via ```pytesseract```                 |

---
# ğŸ’¡ How it Works

1. **User Uploads File** â†’ Text is extracted using format-aware logic.
2. **Summarizer (BigBird Pegasus)** simplifies legal jargon to easy language.
3. **RAG Workflow** embeds text and queries using Ollama and Pinecone.
4. **Mistral LLM** generates accurate and contextual legal answers.


---
# ğŸš€ Technologies Used

| Component         | Technology                   |
|-------------------|------------------------------|
| Backend           | Python + Flask               |
| LLM               | Mistral 7B (Ollama)          |
| Summarizer        | BigBird Pegasus              |
| Embedding Store   | Pinecone Vector DB           |
| OCR               | Tesseract                    |
| File Handling     | PyMuPDF, python-docx         |
| Language Detection| langdetect                   |

---
# ğŸŒ Customization

To switch to other local models (e.g., Mixtral, LLaMA), just change the model name inside `ollama_wrapper.py`:

```python
# Edit this line to switch models
model = "mistral"  # replace with Ollama model tag like mixtral, llama3, etc.
```
---
# ğŸ¤ Contributing
Pull requests and feedback are welcome! If you find bugs or want features, raise an issue.

